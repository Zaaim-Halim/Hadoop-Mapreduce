package zaaim.halim;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class TripletReducer extends Reducer<Text,Pair<IntWritable, IntWritable>,Text,IntWritable>{
	/*private IntWritable result = new IntWritable();

	public void reduce(Text key ,Iterable<IntWritable> values,Context context)
			throws IOException, InterruptedException {
		int sum = 0;
		for (IntWritable val : values) {
			sum += val.get();
		}
		result.set(sum);
		context.write(key, result);
	}*/
	private IntWritable count = new  IntWritable();
	private Text output = new Text();

	public void reduce(Text key ,Iterable<Pair<IntWritable, IntWritable>> pairs,Context context)
			throws IOException, InterruptedException {
        
		for (Pair<IntWritable, IntWritable> val : pairs) {
			output.set(key.toString() + "\t" + val.getT1().get());
			int sum = 0;
			for(Pair<IntWritable, IntWritable> v : pairs)
			{
				sum = sum + v.getT2().get();
			}
			count.set(sum);
			context.write(output, count);
		}

	}

}
