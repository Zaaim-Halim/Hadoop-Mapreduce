package com.hadoop;

import java.io.IOException;
import java.util.Arrays;
import java.util.StringTokenizer;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;


public class AnagramMapper extends Mapper<LongWritable,Text,Text,IntWritable> {
	private Text word = new Text();
    private Text sortedText = new Text();
    private Text orginalText = new Text();
	public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
		
		
		StringTokenizer itr = new StringTokenizer(value.toString());
	      while (itr.hasMoreTokens()) {
	        word.set(itr.nextToken());
	        char[] wordChars = word.toString().toCharArray();
	        Arrays.sort(wordChars);
	        String sortedWord = new String(wordChars);
	        sortedText.set(sortedWord);
	        orginalText.set(word);
	        System.out.println(sortedText+" "+orginalText);
	        context.write(sortedText, orginalText);
	        context.
	      }
	}

}
